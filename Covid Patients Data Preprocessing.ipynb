{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages imported\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import random\n",
    "import seaborn as sns\n",
    "import os.path as path\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.font_manager\n",
    "import matplotlib.pyplot as plt # graphs plotting\n",
    "from Bio import SeqIO # some BioPython that will come in handy\n",
    "#matplotlib inline\n",
    "import numpy\n",
    "import csv \n",
    "\n",
    "from matplotlib import rc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from numpy import mean\n",
    "\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import statistics\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "import math\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# for Arial typefont\n",
    "matplotlib.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "\n",
    "## for Palatino and other serif fonts use:\n",
    "# rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "# matplotlib.rcParams['mathtext.fontset'] = 'cm'\n",
    "\n",
    "## for LaTeX typefont\n",
    "# matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "# matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "## for another LaTeX typefont\n",
    "# rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "\n",
    "# rc('text', usetex = True)\n",
    "\n",
    "print(\"Packages imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://data.cdc.gov/Case-Surveillance/COVID-19-Case-Surveillance-Public-Use-Data-with-Ge/n8mc-b4w4/data\n",
    "\n",
    "read_path = \"C:/Users/sali85/Desktop/COVID-19_Case_Surveillance_Public_Use_Data_with_Geography.csv\"\n",
    "\n",
    "dataset_full = []\n",
    "# host_names_ne = []\n",
    "\n",
    "with open(read_path) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        tmp = row\n",
    "        dataset_full.append(tmp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29851451"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = dataset_full[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021-07',\n",
       " 'VT',\n",
       " '50',\n",
       " 'WASHINGTON',\n",
       " '48477',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " '0',\n",
       " '',\n",
       " 'Missing',\n",
       " 'Yes',\n",
       " 'Laboratory-confirmed case',\n",
       " 'Asymptomatic',\n",
       " 'No',\n",
       " 'Missing',\n",
       " 'No',\n",
       " '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if(aa[5]=='NA' and aa[0]!='NA'):\n",
    "    print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_reduced = []\n",
    "for i in range(1,len(dataset_full)):\n",
    "    tmp = dataset_full[i]\n",
    "    if tmp[0]!=\"NA\" and tmp[1]!=\"NA\" and tmp[2]!=\"NA\" and tmp[3]!=\"NA\" and tmp[4]!=\"NA\" and tmp[5]!=\"NA\" and tmp[6]!=\"NA\" and tmp[7]!=\"NA\" and tmp[8]!=\"NA\" and tmp[9]!=\"NA\" and tmp[10]!=\"NA\" and tmp[11]!=\"NA\" and tmp[12]!=\"NA\" and tmp[13]!=\"NA\" and tmp[14]!=\"NA\" and tmp[15]!=\"NA\" and tmp[16]!=\"NA\" and tmp[17]!=\"NA\" and tmp[18]!=\"NA\":\n",
    "        if tmp[0]!=\"\" and tmp[1]!=\"\" and tmp[2]!=\"\" and tmp[3]!=\"\" and tmp[4]!=\"\" and tmp[5]!=\"\" and tmp[6]!=\"\" and tmp[7]!=\"\" and tmp[8]!=\"\" and tmp[9]!=\"\" and tmp[10]!=\"\" and tmp[11]!=\"\" and tmp[12]!=\"\" and tmp[13]!=\"\" and tmp[14]!=\"\" and tmp[15]!=\"\" and tmp[16]!=\"\" and tmp[17]!=\"\" and tmp[18]!=\"\":\n",
    "            dataset_reduced.append(tmp)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737864"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_reduced_2 = []\n",
    "for i in range(1,len(dataset_reduced)):\n",
    "    tmp = dataset_reduced[i]\n",
    "    if tmp[0]!=\"Missing\" and tmp[1]!=\"Missing\" and tmp[2]!=\"Missing\" and tmp[3]!=\"Missing\" and tmp[4]!=\"Missing\" and tmp[5]!=\"Missing\" and tmp[6]!=\"Missing\" and tmp[7]!=\"Missing\" and tmp[8]!=\"Missing\" and tmp[9]!=\"Missing\" and tmp[10]!=\"Missing\" and tmp[11]!=\"Missing\" and tmp[12]!=\"Missing\" and tmp[13]!=\"Missing\" and tmp[14]!=\"Missing\" and tmp[15]!=\"Missing\" and tmp[16]!=\"Missing\" and tmp[17]!=\"Missing\" and tmp[18]!=\"Missing\":\n",
    "        dataset_reduced_2.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95984"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_reduced_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_data = np.array(dataset_reduced_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"E:\\RA\\Death Classification\\Dataset/CDC_Data.npy\",arr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data = np.load(\"E:\\RA\\Death Classification\\Dataset/CDC_Data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95984"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(covid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = []\n",
    "for i in range(len(covid_data)):\n",
    "    tmp = covid_data[i]\n",
    "    aa.append(tmp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unq = list(np.unique(aa))\n",
    "len(unq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unq.index(\"ASHTABULA\")\n",
    "\n",
    "aaa = []\n",
    "for i in range(len(covid_data)):\n",
    "    tmp = unq.index(aa[i])\n",
    "    aaa.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(aaa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writting Frequency Vectors\n"
     ]
    }
   ],
   "source": [
    "print(\"Writting Frequency Vectors\")   \n",
    "write_path_11 = \"E:/RA/Death Classification/Dataset/tmp.csv\"\n",
    "\n",
    "with open(write_path_11, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for ij in range(0,len(aaa)):\n",
    "        ccv = aaa[ij]\n",
    "        writer.writerow([ccv])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Code Starts From Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = \"E:/RA/Death Classification/Dataset/CDC_Data_int_converted - Copy.csv\"\n",
    "dataset_final = []\n",
    "\n",
    "with open(read_path) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        tmp = row\n",
    "        dataset_final.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95984, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_final),len(dataset_final[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "attributes = []\n",
    "for i in range(0,len(dataset_final)):\n",
    "    tmp = dataset_final[i]\n",
    "    tmp_2 = tmp[0:19]\n",
    "    tmp_arr = []\n",
    "    for j in range(0,len(tmp_2)):\n",
    "        tmp_arr.append(int(tmp_2[j]))\n",
    "    attributes.append(tmp_arr)\n",
    "    labels.append(tmp[19])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_int = []\n",
    "\n",
    "for i in range(0,len(labels)):\n",
    "    if labels[i]==\"Yes\":\n",
    "        labels_int.append(1)\n",
    "    elif labels[i]==\"No\":\n",
    "        labels_int.append(2)\n",
    "    else:\n",
    "        labels_int.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[4]\n",
    "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
    "\n",
    "    unique_class = set(actual_class)\n",
    "    roc_auc_dict = {}\n",
    "    for per_class in unique_class:\n",
    "        #creating a list of all the classes except the current class \n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "        #marking the current class as 1 and all other classes as 0\n",
    "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "        #using the sklearn metrics method to calculate the roc_auc_score\n",
    "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "    \n",
    "    \n",
    "    check = pd.DataFrame(roc_auc_dict.items())\n",
    "    return mean(check)\n",
    "\n",
    "def svm_fun_kernel(X_train,y_train,X_test,y_test,kernel_mat):\n",
    "\n",
    "#     clf = svm.SVC()\n",
    "    clf = svm.SVC(kernel=kernel_mat)\n",
    "    \n",
    "    #Train the model using the training sets\n",
    "    clf.fit(kernel_mat, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    svm_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"SVM Accuracy:\",svm_acc)\n",
    "    \n",
    "    svm_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Precision:\",svm_prec)\n",
    "    \n",
    "    svm_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Recall:\",svm_recall)\n",
    "\n",
    "    svm_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM F1 Weighted:\",svm_f1_weighted)\n",
    "    \n",
    "    svm_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"SVM F1 macro:\",svm_f1_macro)\n",
    "    \n",
    "    svm_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"SVM F1 micro:\",svm_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix SVM : \\n\", confuse)\n",
    "    print(\"SVM Kernel Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "#    print(macro_roc_auc_ovo[1])\n",
    "    check = [svm_acc,svm_prec,svm_recall,svm_f1_weighted,svm_f1_macro,svm_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "    \n",
    "# In[5]\n",
    "##########################  SVM Classifier  ################################\n",
    "def svm_fun(X_train,y_train,X_test,y_test):\n",
    "    #Create a svm Classifier\n",
    "    clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    svm_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"SVM Accuracy:\",svm_acc)\n",
    "    \n",
    "    svm_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Precision:\",svm_prec)\n",
    "    \n",
    "    svm_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Recall:\",svm_recall)\n",
    "\n",
    "    svm_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM F1 Weighted:\",svm_f1_weighted)\n",
    "    \n",
    "    svm_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"SVM F1 macro:\",svm_f1_macro)\n",
    "    \n",
    "    svm_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"SVM F1 micro:\",svm_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix SVM : \\n\", confuse)\n",
    "    print(\"SVM Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "#    print(macro_roc_auc_ovo[1])\n",
    "    check = [svm_acc,svm_prec,svm_recall,svm_f1_weighted,svm_f1_macro,svm_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "    \n",
    "\n",
    "\n",
    "# In[5]\n",
    "##########################  NB Classifier  ################################\n",
    "def gaus_nb_fun(X_train,y_train,X_test,y_test):\n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "    NB_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Gaussian NB Accuracy:\",NB_acc)\n",
    "\n",
    "    NB_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Gaussian NB Precision:\",NB_prec)\n",
    "    \n",
    "    NB_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Gaussian NB Recall:\",NB_recall)\n",
    "    \n",
    "    NB_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Gaussian NB F1 weighted:\",NB_f1_weighted)\n",
    "    \n",
    "    NB_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Gaussian NB F1 macro:\",NB_f1_macro)\n",
    "    \n",
    "    NB_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Gaussian NB F1 micro:\",NB_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix NB : \\n\", confuse)\n",
    "    print(\"NB Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    check = [NB_acc,NB_prec,NB_recall,NB_f1_weighted,NB_f1_macro,NB_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "##########################  MLP Classifier  ################################\n",
    "def mlp_fun(X_train,y_train,X_test,y_test):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)  \n",
    "    X_test_2 = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    # Finally for the MLP- Multilayer Perceptron\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)  \n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    y_pred = mlp.predict(X_test_2)\n",
    "    \n",
    "    MLP_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"MLP Accuracy:\",MLP_acc)\n",
    "    \n",
    "    MLP_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"MLP Precision:\",MLP_prec)\n",
    "    \n",
    "    MLP_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"MLP Recall:\",MLP_recall)\n",
    "    \n",
    "    MLP_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"MLP F1:\",MLP_f1_weighted)\n",
    "    \n",
    "    MLP_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"MLP F1:\",MLP_f1_macro)\n",
    "    \n",
    "    MLP_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"MLP F1:\",MLP_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix MLP : \\n\", confuse)\n",
    "    print(\"MLP Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [MLP_acc,MLP_prec,MLP_recall,MLP_f1_weighted,MLP_f1_macro,MLP_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "##########################  knn Classifier  ################################\n",
    "def knn_fun(X_train,y_train,X_test,y_test):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    knn_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Knn Accuracy:\",knn_acc)\n",
    "    \n",
    "    knn_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Knn Precision:\",knn_prec)\n",
    "    \n",
    "    knn_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Knn Recall:\",knn_recall)\n",
    "    \n",
    "    knn_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Knn F1 weighted:\",knn_f1_weighted)\n",
    "    \n",
    "    knn_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Knn F1 macro:\",knn_f1_macro)\n",
    "    \n",
    "    knn_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Knn F1 micro:\",knn_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix KNN : \\n\", confuse)\n",
    "    print(\"KNN Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [knn_acc,knn_prec,knn_recall,knn_f1_weighted,knn_f1_macro,knn_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "##########################  Random Forest Classifier  ################################\n",
    "def rf_fun(X_train,y_train,X_test,y_test):\n",
    "    # Import the model we are using\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf = RandomForestClassifier(n_estimators = 100)\n",
    "    # Train the model on training data\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    fr_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Random Forest Accuracy:\",fr_acc)\n",
    "    \n",
    "    fr_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Random Forest Precision:\",fr_prec)\n",
    "    \n",
    "    fr_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Random Forest Recall:\",fr_recall)\n",
    "    \n",
    "    fr_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Random Forest F1 weighted:\",fr_f1_weighted)\n",
    "    \n",
    "    fr_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Random Forest F1 macro:\",fr_f1_macro)\n",
    "    \n",
    "    fr_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Random Forest F1 micro:\",fr_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix RF : \\n\", confuse)\n",
    "    print(\"RF Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [fr_acc,fr_prec,fr_recall,fr_f1_weighted,fr_f1_macro,fr_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "    ##########################  Logistic Regression Classifier  ################################\n",
    "def lr_fun(X_train,y_train,X_test,y_test):\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    LR_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Logistic Regression Accuracy:\",LR_acc)\n",
    "    \n",
    "    LR_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Precision:\",LR_prec)\n",
    "    \n",
    "    LR_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Recall:\",LR_recall)\n",
    "    \n",
    "    LR_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression F1 weighted:\",LR_f1_weighted)\n",
    "    \n",
    "    LR_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Logistic Regression F1 macro:\",LR_f1_macro)\n",
    "    \n",
    "    LR_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Logistic Regression F1 micro:\",LR_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix LR : \\n\", confuse)\n",
    "    print(\"LR Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [LR_acc,LR_prec,LR_recall,LR_f1_weighted,LR_f1_macro,LR_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "\n",
    "def fun_decision_tree(X_train,y_train,X_test,y_test):\n",
    "    from sklearn import tree\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier()    \n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    dt_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Logistic Regression Accuracy:\",LR_acc)\n",
    "    \n",
    "    dt_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Precision:\",LR_prec)\n",
    "    \n",
    "    dt_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Recall:\",LR_recall)\n",
    "    \n",
    "    dt_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression F1 weighted:\",LR_f1_weighted)\n",
    "    \n",
    "    dt_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Logistic Regression F1 macro:\",LR_f1_macro)\n",
    "    \n",
    "    dt_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Logistic Regression F1 micro:\",LR_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix DT : \\n\", confuse)\n",
    "    print(\"DT Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [dt_acc,dt_prec,dt_recall,dt_f1_weighted,dt_f1_macro,dt_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(attributes)\n",
    "y =  np.array(labels_int)\n",
    "\n",
    "X_orig = np.array(attributes)\n",
    "\n",
    "counter = 1\n",
    "# print(\"Accuracy   Precision   Recall   F1 (weighted)   F1 (Macro)   F1 (Micro)   ROC AUC\")\n",
    "svm_table = []\n",
    "gauu_nb_table = []\n",
    "mlp_table = []\n",
    "knn_table = []\n",
    "rf_table = []\n",
    "lr_table = []\n",
    "dt_table = []\n",
    "\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.3)\n",
    "sss.get_n_splits(X, y)\n",
    "train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67188, 19), (28796, 19))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (X_test[0])\n",
    "# for i in range(0,len(a)):\n",
    "#     print((a[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix NB : \n",
      " [[ 1397    20   174]\n",
      " [   57   195   114]\n",
      " [ 4842   698 21299]]\n",
      "NB Class Wise Accuracy :  [0.87806411 0.53278689 0.79358396]\n",
      "NB Time :  0.18693579999990106\n",
      "Confusion Matrix MLP : \n",
      " [[ 1107     0   484]\n",
      " [   11    54   301]\n",
      " [  889    44 25906]]\n",
      "MLP Class Wise Accuracy :  [0.69578881 0.14754098 0.96523715]\n",
      "MLP Time :  38.59970339999995\n",
      "Confusion Matrix KNN : \n",
      " [[  855     3   733]\n",
      " [   10    81   275]\n",
      " [  535   106 26198]]\n",
      "KNN Class Wise Accuracy :  [0.53739786 0.22131148 0.97611684]\n",
      "KNN Time :  4.322970899999973\n",
      "Confusion Matrix RF : \n",
      " [[  867     2   722]\n",
      " [    8   103   255]\n",
      " [  456   121 26262]]\n",
      "RF Class Wise Accuracy :  [0.54494029 0.28142077 0.97850143]\n",
      "RF Time :  4.862974000000122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix LR : \n",
      " [[    0     0  1591]\n",
      " [    0     0   366]\n",
      " [    0     0 26839]]\n",
      "LR Class Wise Accuracy :  [0. 0. 1.]\n",
      "LR Time :  0.900952899999993\n",
      "Confusion Matrix DT : \n",
      " [[  967     5   619]\n",
      " [   13   115   238]\n",
      " [  683   247 25909]]\n",
      "DT Class Wise Accuracy :  [0.60779384 0.31420765 0.96534893]\n",
      "DT Time :  0.34448429999997643\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "gauu_nb_return = gaus_nb_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"NB Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "mlp_return = mlp_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"MLP Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "knn_return = knn_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"KNN Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "rf_return = rf_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"RF Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "lr_return = lr_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"LR Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "dt_return = fun_decision_tree(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"DT Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "svm_return = svm_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"SVM Time : \", stop - start) \n",
    "\n",
    "gauu_nb_table.append(gauu_nb_return)\n",
    "mlp_table.append(mlp_return)\n",
    "knn_table.append(knn_return)\n",
    "rf_table.append(rf_return)\n",
    "lr_table.append(lr_return)\n",
    "dt_table.append(dt_return)\n",
    "svm_table.append(svm_return)\n",
    "     \n",
    "svm_table_final = DataFrame(svm_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "gauu_nb_table_final = DataFrame(gauu_nb_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "mlp_table_final = DataFrame(mlp_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "knn_table_final = DataFrame(knn_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "rf_table_final = DataFrame(rf_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "lr_table_final = DataFrame(lr_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "\n",
    "dt_table_final = DataFrame(dt_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 (weighted)</th>\n",
       "      <th>F1 (Macro)</th>\n",
       "      <th>F1 (Micro)</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.931796</td>\n",
       "      <td>0.916067</td>\n",
       "      <td>0.931796</td>\n",
       "      <td>0.922241</td>\n",
       "      <td>0.463193</td>\n",
       "      <td>0.931796</td>\n",
       "      <td>0.603208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.786186</td>\n",
       "      <td>0.934514</td>\n",
       "      <td>0.786186</td>\n",
       "      <td>0.837678</td>\n",
       "      <td>0.493988</td>\n",
       "      <td>0.786186</td>\n",
       "      <td>0.802115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.941554</td>\n",
       "      <td>0.932419</td>\n",
       "      <td>0.941554</td>\n",
       "      <td>0.935072</td>\n",
       "      <td>0.594290</td>\n",
       "      <td>0.941554</td>\n",
       "      <td>0.664920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.943951</td>\n",
       "      <td>0.937328</td>\n",
       "      <td>0.943951</td>\n",
       "      <td>0.939806</td>\n",
       "      <td>0.606581</td>\n",
       "      <td>0.943951</td>\n",
       "      <td>0.691581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.945617</td>\n",
       "      <td>0.940163</td>\n",
       "      <td>0.945617</td>\n",
       "      <td>0.942239</td>\n",
       "      <td>0.640707</td>\n",
       "      <td>0.945617</td>\n",
       "      <td>0.712880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.933150</td>\n",
       "      <td>0.870770</td>\n",
       "      <td>0.933150</td>\n",
       "      <td>0.900882</td>\n",
       "      <td>0.321806</td>\n",
       "      <td>0.933150</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.936727</td>\n",
       "      <td>0.937597</td>\n",
       "      <td>0.936727</td>\n",
       "      <td>0.937114</td>\n",
       "      <td>0.624576</td>\n",
       "      <td>0.936727</td>\n",
       "      <td>0.733119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Precision    Recall  F1 (weighted)  F1 (Macro)  F1 (Micro)  \\\n",
       "SVM  0.931796   0.916067  0.931796       0.922241    0.463193    0.931796   \n",
       "NB   0.786186   0.934514  0.786186       0.837678    0.493988    0.786186   \n",
       "MLP  0.941554   0.932419  0.941554       0.935072    0.594290    0.941554   \n",
       "KNN  0.943951   0.937328  0.943951       0.939806    0.606581    0.943951   \n",
       "RF   0.945617   0.940163  0.945617       0.942239    0.640707    0.945617   \n",
       "LR   0.933150   0.870770  0.933150       0.900882    0.321806    0.933150   \n",
       "DT   0.936727   0.937597  0.936727       0.937114    0.624576    0.936727   \n",
       "\n",
       "      ROC AUC  \n",
       "SVM  0.603208  \n",
       "NB   0.802115  \n",
       "MLP  0.664920  \n",
       "KNN  0.691581  \n",
       "RF   0.712880  \n",
       "LR   0.500000  \n",
       "DT   0.733119  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking average of all k-fold performance values\n",
    "final_mean_mat = []\n",
    "\n",
    "final_mean_mat.append(np.transpose((list(svm_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(gauu_nb_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(mlp_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(knn_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(rf_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(lr_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(dt_table_final.mean()))))\n",
    "\n",
    "final_avg_mat = DataFrame(final_mean_mat,columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"], \n",
    "                          index=[\"SVM\",\"NB\",\"MLP\",\"KNN\",\"RF\",\"LR\",\"DT\"])\n",
    "\n",
    "final_avg_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boruta for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "      <th>c10</th>\n",
       "      <th>c11</th>\n",
       "      <th>c12</th>\n",
       "      <th>c13</th>\n",
       "      <th>c14</th>\n",
       "      <th>c15</th>\n",
       "      <th>c16</th>\n",
       "      <th>c17</th>\n",
       "      <th>c18</th>\n",
       "      <th>c19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>63</td>\n",
       "      <td>20057</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>180</td>\n",
       "      <td>20209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>75</td>\n",
       "      <td>20079</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>102</td>\n",
       "      <td>20111</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>20169</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95979</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>32003</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95980</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>32003</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95981</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>32003</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95982</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>32003</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95983</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>32003</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95984 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         c1  c2  c3  c4   c5     c6  c7  c8  c9  c10  c11  c12  c13  c14  c15  \\\n",
       "0      2020   4   6  20   63  20057   2   1   0    1    0    0    0    0    1   \n",
       "1      2020   7   6  20  180  20209   2   2   0    1    0    0    3    1    1   \n",
       "2      2020  11   6  20   75  20079   2   1   6    1    1    0    4    1    2   \n",
       "3      2020   8   6  20  102  20111   2   2   6    1    0    0    2    1    1   \n",
       "4      2020   7   6  20  140  20169   2   1   6    1    0    0    0    0    1   \n",
       "...     ...  ..  ..  ..  ...    ...  ..  ..  ..  ...  ...  ...  ...  ...  ...   \n",
       "95979  2020   9  11  32   35  32003   3   1   6    0    0    0    2    1    1   \n",
       "95980  2020   9  11  32   35  32003   3   1   6    0    0    0    4    1    1   \n",
       "95981  2020   9  11  32   35  32003   3   1   6    0    0    0    4    1    1   \n",
       "95982  2020   9  11  32   35  32003   3   1   6    0    0    0    2    1    1   \n",
       "95983  2020   9  11  32   35  32003   3   1   6    0    0    0    2    1    1   \n",
       "\n",
       "       c16  c17  c18  c19  \n",
       "0        1    2    2    1  \n",
       "1        1    2    2    2  \n",
       "2        1    2    2    2  \n",
       "3        1    2    2    2  \n",
       "4        1    2    0    1  \n",
       "...    ...  ...  ...  ...  \n",
       "95979    1    2    2    1  \n",
       "95980    1    2    2    1  \n",
       "95981    1    2    2    1  \n",
       "95982    1    2    2    1  \n",
       "95983    1    2    2    1  \n",
       "\n",
       "[95984 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### make X_shadow by randomly permuting each column of X\n",
    "X_df = pd.DataFrame(X)\n",
    "X_df.columns = [\"c1\",\"c2\",\"c3\",\"c4\",\"c5\",\"c6\",\"c7\",\"c8\",\"c9\",\"c10\",\"c11\",\"c12\",\"c13\",\"c14\",\"c15\",\"c16\",\"c17\",\"c18\",\"c19\"]\n",
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X_shadow = X_df.apply(np.random.permutation)\n",
    "X_shadow.columns = ['shadow_' + feat for feat in X_df.columns]\n",
    "### make X_boruta by appending X_shadow to X\n",
    "X_boruta = pd.concat([X_df, X_shadow], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95984"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_boruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>...</th>\n",
       "      <th>shadow_</th>\n",
       "      <th>shadow_</th>\n",
       "      <th>shadow_</th>\n",
       "      <th>shadow_</th>\n",
       "      <th>shadow_</th>\n",
       "      <th>shadow_</th>\n",
       "      <th>shadow_</th>\n",
       "      <th>shadow_</th>\n",
       "      <th>shadow_</th>\n",
       "      <th>shadow_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>63</td>\n",
       "      <td>20057</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>180</td>\n",
       "      <td>20209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>75</td>\n",
       "      <td>20079</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>102</td>\n",
       "      <td>20111</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>20169</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95979</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>32003</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95980</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>32003</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95981</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>32003</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95982</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>32003</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95983</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>32003</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95984 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ...  shadow_  shadow_  \\\n",
       "0      2020   4   6  20   63  20057  2  1  0  1  ...        2        0   \n",
       "1      2020   7   6  20  180  20209  2  2  0  1  ...        2        0   \n",
       "2      2020  11   6  20   75  20079  2  1  6  1  ...        2        0   \n",
       "3      2020   8   6  20  102  20111  2  2  6  1  ...        2        0   \n",
       "4      2020   7   6  20  140  20169  2  1  6  1  ...        2        1   \n",
       "...     ...  ..  ..  ..  ...    ... .. .. .. ..  ...      ...      ...   \n",
       "95979  2020   9  11  32   35  32003  3  1  6  0  ...        2        1   \n",
       "95980  2020   9  11  32   35  32003  3  1  6  0  ...        2        0   \n",
       "95981  2020   9  11  32   35  32003  3  1  6  0  ...        2        0   \n",
       "95982  2020   9  11  32   35  32003  3  1  6  0  ...        2        1   \n",
       "95983  2020   9  11  32   35  32003  3  1  6  0  ...        2        0   \n",
       "\n",
       "       shadow_  shadow_  shadow_  shadow_  shadow_  shadow_  shadow_  shadow_  \n",
       "0            0        1        1        1        1        2        2        1  \n",
       "1            0        4        1        1        1        2        2        1  \n",
       "2            0        4        1        2        1        2        2        1  \n",
       "3            0        4        1        1        1        2        2        2  \n",
       "4            0        1        1        1        1        2        0        1  \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...  \n",
       "95979        0        0        1        1        1        2        2        1  \n",
       "95980        0        2        1        1        1        2        2        1  \n",
       "95981        0        3        1        1        1        2        2        1  \n",
       "95982        0        1        1        1        1        2        2        1  \n",
       "95983        0        0        1        1        1        2        2        1  \n",
       "\n",
       "[95984 rows x 38 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_boruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "### fit a random forest (suggested max_depth between 3 and 7)\n",
    "forest = RandomForestRegressor(max_depth = 5, random_state = 42)\n",
    "forest.fit(X_boruta, y)\n",
    "### store feature importances\n",
    "feat_imp_X = forest.feature_importances_[:len(X_df.columns)]\n",
    "feat_imp_shadow = forest.feature_importances_[len(X_df.columns):]\n",
    "### compute hits\n",
    "hits = feat_imp_X > feat_imp_shadow.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        True, False, False,  True, False, False, False,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_tmp = []\n",
    "\n",
    "for i in range(len(hits)):\n",
    "    if(hits[i]==True):\n",
    "        indices_tmp.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 9, 12, 16, 17, 18]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(indices_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_boruta_data = np.array(X_df.iloc[:,indices_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_boruta_data\n",
    "y =  np.array(labels_int)\n",
    "\n",
    "\n",
    "counter = 1\n",
    "# print(\"Accuracy   Precision   Recall   F1 (weighted)   F1 (Macro)   F1 (Micro)   ROC AUC\")\n",
    "svm_table = []\n",
    "gauu_nb_table = []\n",
    "mlp_table = []\n",
    "knn_table = []\n",
    "rf_table = []\n",
    "lr_table = []\n",
    "dt_table = []\n",
    "\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.3)\n",
    "sss.get_n_splits(X, y)\n",
    "train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67188, 11), (28796, 11))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-691b4934c597>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix NB : \n",
      " [[ 1361    28   181]\n",
      " [   36   186   161]\n",
      " [ 3747   626 22470]]\n",
      "NB Class Wise Accuracy :  [0.86687898 0.48563969 0.83708974]\n",
      "NB Time :  0.14972530000000006\n",
      "Confusion Matrix MLP : \n",
      " [[  670     3   897]\n",
      " [    3    70   310]\n",
      " [  454    57 26332]]\n",
      "MLP Class Wise Accuracy :  [0.42675159 0.18276762 0.98096338]\n",
      "MLP Time :  22.769935799999985\n",
      "Confusion Matrix KNN : \n",
      " [[  856     2   712]\n",
      " [    6    92   285]\n",
      " [  531    86 26226]]\n",
      "KNN Class Wise Accuracy :  [0.54522293 0.24020888 0.97701449]\n",
      "KNN Time :  1.8145791999999972\n",
      "Confusion Matrix RF : \n",
      " [[  868     0   702]\n",
      " [    8   108   267]\n",
      " [  467   108 26268]]\n",
      "RF Class Wise Accuracy :  [0.55286624 0.28198433 0.97857915]\n",
      "RF Time :  3.3464486999999963\n",
      "Confusion Matrix LR : \n",
      " [[   21     6  1543]\n",
      " [    1     2   380]\n",
      " [   41    27 26775]]\n",
      "LR Class Wise Accuracy :  [0.0133758  0.00522193 0.99746675]\n",
      "LR Time :  0.9686672999999928\n",
      "Confusion Matrix DT : \n",
      " [[  904     1   665]\n",
      " [    8   125   250]\n",
      " [  570   162 26111]]\n",
      "DT Class Wise Accuracy :  [0.57579618 0.32637076 0.97273032]\n",
      "DT Time :  0.22743930000001455\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "gauu_nb_return = gaus_nb_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"NB Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "mlp_return = mlp_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"MLP Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "knn_return = knn_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"KNN Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "rf_return = rf_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"RF Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "lr_return = lr_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"LR Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "dt_return = fun_decision_tree(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"DT Time : \", stop - start) \n",
    "\n",
    "# start = timeit.default_timer()\n",
    "# svm_return = svm_fun(X_train,y_train,X_test,y_test)\n",
    "# stop = timeit.default_timer()\n",
    "# print(\"SVM Time : \", stop - start) \n",
    "\n",
    "gauu_nb_table.append(gauu_nb_return)\n",
    "mlp_table.append(mlp_return)\n",
    "knn_table.append(knn_return)\n",
    "rf_table.append(rf_return)\n",
    "lr_table.append(lr_return)\n",
    "dt_table.append(dt_return)\n",
    "# svm_table.append(svm_return)\n",
    "     \n",
    "# svm_table_final = DataFrame(svm_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "#                                                 \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "gauu_nb_table_final = DataFrame(gauu_nb_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "mlp_table_final = DataFrame(mlp_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "knn_table_final = DataFrame(knn_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "rf_table_final = DataFrame(rf_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "lr_table_final = DataFrame(lr_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "\n",
    "dt_table_final = DataFrame(dt_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 (weighted)</th>\n",
       "      <th>F1 (Macro)</th>\n",
       "      <th>F1 (Micro)</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.834039</td>\n",
       "      <td>0.935573</td>\n",
       "      <td>0.834039</td>\n",
       "      <td>0.869813</td>\n",
       "      <td>0.538212</td>\n",
       "      <td>0.834039</td>\n",
       "      <td>0.808755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.940131</td>\n",
       "      <td>0.930897</td>\n",
       "      <td>0.940131</td>\n",
       "      <td>0.933448</td>\n",
       "      <td>0.579387</td>\n",
       "      <td>0.940131</td>\n",
       "      <td>0.658927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.943673</td>\n",
       "      <td>0.938340</td>\n",
       "      <td>0.943673</td>\n",
       "      <td>0.940199</td>\n",
       "      <td>0.624920</td>\n",
       "      <td>0.943673</td>\n",
       "      <td>0.704855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.946104</td>\n",
       "      <td>0.940903</td>\n",
       "      <td>0.946104</td>\n",
       "      <td>0.942852</td>\n",
       "      <td>0.642667</td>\n",
       "      <td>0.946104</td>\n",
       "      <td>0.716004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.930615</td>\n",
       "      <td>0.888648</td>\n",
       "      <td>0.930615</td>\n",
       "      <td>0.900291</td>\n",
       "      <td>0.333147</td>\n",
       "      <td>0.930615</td>\n",
       "      <td>0.504787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.942492</td>\n",
       "      <td>0.939648</td>\n",
       "      <td>0.942492</td>\n",
       "      <td>0.940931</td>\n",
       "      <td>0.644801</td>\n",
       "      <td>0.942492</td>\n",
       "      <td>0.729903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Precision    Recall  F1 (weighted)  F1 (Macro)  F1 (Micro)  \\\n",
       "NB   0.834039   0.935573  0.834039       0.869813    0.538212    0.834039   \n",
       "MLP  0.940131   0.930897  0.940131       0.933448    0.579387    0.940131   \n",
       "KNN  0.943673   0.938340  0.943673       0.940199    0.624920    0.943673   \n",
       "RF   0.946104   0.940903  0.946104       0.942852    0.642667    0.946104   \n",
       "LR   0.930615   0.888648  0.930615       0.900291    0.333147    0.930615   \n",
       "DT   0.942492   0.939648  0.942492       0.940931    0.644801    0.942492   \n",
       "\n",
       "      ROC AUC  \n",
       "NB   0.808755  \n",
       "MLP  0.658927  \n",
       "KNN  0.704855  \n",
       "RF   0.716004  \n",
       "LR   0.504787  \n",
       "DT   0.729903  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking average of all k-fold performance values\n",
    "final_mean_mat = []\n",
    "\n",
    "# final_mean_mat.append(np.transpose((list(svm_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(gauu_nb_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(mlp_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(knn_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(rf_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(lr_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(dt_table_final.mean()))))\n",
    "\n",
    "final_avg_mat = DataFrame(final_mean_mat,columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"], \n",
    "                          index=[\"NB\",\"MLP\",\"KNN\",\"RF\",\"LR\",\"DT\"])\n",
    "\n",
    "final_avg_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 19\n",
      "selected features: 5\n",
      "features with coefficients shrank to zero: 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = X_orig\n",
    "y =  np.array(labels_int)\n",
    "\n",
    "ridge_data = pd.DataFrame(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    ridge_data,y,\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.fillna(0))\n",
    "\n",
    "# L1 = Lasso, L2 = Ridge\n",
    "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l2', solver='liblinear'))\n",
    "sel_.fit(scaler.transform(X_train.fillna(0)), y_train)\n",
    "\n",
    "sel_.get_support()\n",
    "\n",
    "selected_feat = X_train.columns[(sel_.get_support())]\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "      np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 19\n",
      "selected features: 5\n",
      "features with coefficients shrank to zero: 3\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.fillna(0))\n",
    "\n",
    "# L1 = Lasso, L2 = Ridge\n",
    "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l2', solver='liblinear'))\n",
    "sel_.fit(scaler.transform(X_train.fillna(0)), y_train)\n",
    "\n",
    "sel_.get_support()\n",
    "\n",
    "selected_feat_ridge = X_train.columns[(sel_.get_support())]\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat_ridge)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "      np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_Regression_data = sel_.transform(ridge_data.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Ridge_Regression_data\n",
    "y =  np.array(labels_int)\n",
    "\n",
    "\n",
    "counter = 1\n",
    "# print(\"Accuracy   Precision   Recall   F1 (weighted)   F1 (Macro)   F1 (Micro)   ROC AUC\")\n",
    "svm_table = []\n",
    "gauu_nb_table = []\n",
    "mlp_table = []\n",
    "knn_table = []\n",
    "rf_table = []\n",
    "lr_table = []\n",
    "dt_table = []\n",
    "\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.3)\n",
    "sss.get_n_splits(X, y)\n",
    "train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix NB : \n",
      " [[ 1303     0   222]\n",
      " [   44    12   342]\n",
      " [ 3905    20 22948]]\n",
      "NB Class Wise Accuracy :  [0.85442623 0.03015075 0.85394262]\n",
      "NB Time :  0.12953089999996337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix MLP : \n",
      " [[    0     0  1525]\n",
      " [    0     0   398]\n",
      " [    0     0 26873]]\n",
      "MLP Class Wise Accuracy :  [0. 0. 1.]\n",
      "MLP Time :  5.658490400000005\n",
      "Confusion Matrix KNN : \n",
      " [[  506     0  1019]\n",
      " [    1    16   381]\n",
      " [  538    21 26314]]\n",
      "KNN Class Wise Accuracy :  [0.33180328 0.04020101 0.97919845]\n",
      "KNN Time :  1.6607721999999967\n",
      "Confusion Matrix RF : \n",
      " [[  721     0   804]\n",
      " [   16     8   374]\n",
      " [  512     3 26358]]\n",
      "RF Class Wise Accuracy :  [0.47278689 0.0201005  0.98083578]\n",
      "RF Time :  2.214795600000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix LR : \n",
      " [[    1     0  1524]\n",
      " [    0     0   398]\n",
      " [   30     0 26843]]\n",
      "LR Class Wise Accuracy :  [6.55737705e-04 0.00000000e+00 9.98883638e-01]\n",
      "LR Time :  0.3383728000000019\n",
      "Confusion Matrix DT : \n",
      " [[  739     0   786]\n",
      " [   16     8   374]\n",
      " [  530     5 26338]]\n",
      "DT Class Wise Accuracy :  [0.48459016 0.0201005  0.98009154]\n",
      "DT Time :  0.15409269999997832\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "gauu_nb_return = gaus_nb_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"NB Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "mlp_return = mlp_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"MLP Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "knn_return = knn_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"KNN Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "rf_return = rf_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"RF Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "lr_return = lr_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"LR Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "dt_return = fun_decision_tree(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"DT Time : \", stop - start) \n",
    "\n",
    "# start = timeit.default_timer()\n",
    "# svm_return = svm_fun(X_train,y_train,X_test,y_test)\n",
    "# stop = timeit.default_timer()\n",
    "# print(\"SVM Time : \", stop - start) \n",
    "\n",
    "gauu_nb_table.append(gauu_nb_return)\n",
    "mlp_table.append(mlp_return)\n",
    "knn_table.append(knn_return)\n",
    "rf_table.append(rf_return)\n",
    "lr_table.append(lr_return)\n",
    "dt_table.append(dt_return)\n",
    "# svm_table.append(svm_return)\n",
    "     \n",
    "# svm_table_final = DataFrame(svm_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "#                                                 \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "gauu_nb_table_final = DataFrame(gauu_nb_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "mlp_table_final = DataFrame(mlp_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "knn_table_final = DataFrame(knn_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "rf_table_final = DataFrame(rf_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "lr_table_final = DataFrame(lr_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "\n",
    "dt_table_final = DataFrame(dt_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 (weighted)</th>\n",
       "      <th>F1 (Macro)</th>\n",
       "      <th>F1 (Micro)</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.842582</td>\n",
       "      <td>0.929156</td>\n",
       "      <td>0.842582</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.450419</td>\n",
       "      <td>0.842582</td>\n",
       "      <td>0.716620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.933220</td>\n",
       "      <td>0.870899</td>\n",
       "      <td>0.933220</td>\n",
       "      <td>0.900983</td>\n",
       "      <td>0.321819</td>\n",
       "      <td>0.933220</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.931935</td>\n",
       "      <td>0.917697</td>\n",
       "      <td>0.931935</td>\n",
       "      <td>0.921599</td>\n",
       "      <td>0.477150</td>\n",
       "      <td>0.931935</td>\n",
       "      <td>0.600445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.940651</td>\n",
       "      <td>0.933919</td>\n",
       "      <td>0.940651</td>\n",
       "      <td>0.932252</td>\n",
       "      <td>0.509277</td>\n",
       "      <td>0.940651</td>\n",
       "      <td>0.640279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.932213</td>\n",
       "      <td>0.872573</td>\n",
       "      <td>0.932213</td>\n",
       "      <td>0.900547</td>\n",
       "      <td>0.322067</td>\n",
       "      <td>0.932213</td>\n",
       "      <td>0.499827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.940582</td>\n",
       "      <td>0.932814</td>\n",
       "      <td>0.940582</td>\n",
       "      <td>0.932520</td>\n",
       "      <td>0.511244</td>\n",
       "      <td>0.940582</td>\n",
       "      <td>0.643560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Precision    Recall  F1 (weighted)  F1 (Macro)  F1 (Micro)  \\\n",
       "NB   0.842582   0.929156  0.842582       0.871212    0.450419    0.842582   \n",
       "MLP  0.933220   0.870899  0.933220       0.900983    0.321819    0.933220   \n",
       "KNN  0.931935   0.917697  0.931935       0.921599    0.477150    0.931935   \n",
       "RF   0.940651   0.933919  0.940651       0.932252    0.509277    0.940651   \n",
       "LR   0.932213   0.872573  0.932213       0.900547    0.322067    0.932213   \n",
       "DT   0.940582   0.932814  0.940582       0.932520    0.511244    0.940582   \n",
       "\n",
       "      ROC AUC  \n",
       "NB   0.716620  \n",
       "MLP  0.500000  \n",
       "KNN  0.600445  \n",
       "RF   0.640279  \n",
       "LR   0.499827  \n",
       "DT   0.643560  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking average of all k-fold performance values\n",
    "final_mean_mat = []\n",
    "\n",
    "# final_mean_mat.append(np.transpose((list(svm_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(gauu_nb_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(mlp_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(knn_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(rf_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(lr_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(dt_table_final.mean()))))\n",
    "\n",
    "final_avg_mat = DataFrame(final_mean_mat,columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"], \n",
    "                          index=[\"NB\",\"MLP\",\"KNN\",\"RF\",\"LR\",\"DT\"])\n",
    "\n",
    "final_avg_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split Done\n",
      "X_train rows =  67188 X_train columns =  10\n",
      "X_test rows =  28796 X_test columns =  10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_approximation import RBFSampler\n",
    "X = X_orig\n",
    "y =  np.array(labels_int)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.3)\n",
    "sss.get_n_splits(X, y)\n",
    "train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "print(\"Train-Test Split Done\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#print(\"Random Fourier Features Starts here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "\n",
    "# start_time = time.time()\n",
    "rbf_feature = RBFSampler(gamma=1, n_components=10)\n",
    "rbf_feature.fit(X_train)\n",
    "X_features_train = rbf_feature.transform(X_train)\n",
    "X_features_test = rbf_feature.transform(X_test)\n",
    "\n",
    "print(\"X_train rows = \",len(X_features_train),\"X_train columns = \",len(X_features_train[0]))\n",
    "print(\"X_test rows = \",len(X_features_test),\"X_test columns = \",len(X_features_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_table = []\n",
    "gauu_nb_table = []\n",
    "mlp_table = []\n",
    "knn_table = []\n",
    "rf_table = []\n",
    "lr_table = []\n",
    "dt_table = []\n",
    "\n",
    "\n",
    "X_train = X_features_train[:]\n",
    "X_test = X_features_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix NB : \n",
      " [[    0     0  1571]\n",
      " [    0     0   359]\n",
      " [    0     0 26866]]\n",
      "NB Class Wise Accuracy :  [0. 0. 1.]\n",
      "NB Time :  0.1442575000000943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix MLP : \n",
      " [[    2     0  1569]\n",
      " [    0     0   359]\n",
      " [    5     0 26861]]\n",
      "MLP Class Wise Accuracy :  [0.00127307 0.         0.99981389]\n",
      "MLP Time :  24.225640500000054\n",
      "Confusion Matrix KNN : \n",
      " [[  414     4  1153]\n",
      " [   11    13   335]\n",
      " [  539    72 26255]]\n",
      "KNN Class Wise Accuracy :  [0.26352642 0.0362117  0.9772575 ]\n",
      "KNN Time :  3.280323699999826\n",
      "Confusion Matrix RF : \n",
      " [[  592     2   977]\n",
      " [    7    56   296]\n",
      " [  334    69 26463]]\n",
      "RF Class Wise Accuracy :  [0.37683004 0.15598886 0.98499963]\n",
      "RF Time :  27.878876999999875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix LR : \n",
      " [[    0     0  1571]\n",
      " [    0     0   359]\n",
      " [    0     0 26866]]\n",
      "LR Class Wise Accuracy :  [0. 0. 1.]\n",
      "LR Time :  0.26108350000004066\n",
      "Confusion Matrix DT : \n",
      " [[  675    12   884]\n",
      " [   21    71   267]\n",
      " [ 1030   354 25482]]\n",
      "DT Class Wise Accuracy :  [0.42966264 0.19777159 0.94848507]\n",
      "DT Time :  1.4616814999999406\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "gauu_nb_return = gaus_nb_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"NB Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "mlp_return = mlp_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"MLP Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "knn_return = knn_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"KNN Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "rf_return = rf_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"RF Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "lr_return = lr_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"LR Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "dt_return = fun_decision_tree(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"DT Time : \", stop - start) \n",
    "\n",
    "# start = timeit.default_timer()\n",
    "# svm_return = svm_fun(X_train,y_train,X_test,y_test)\n",
    "# stop = timeit.default_timer()\n",
    "# print(\"SVM Time : \", stop - start) \n",
    "\n",
    "gauu_nb_table.append(gauu_nb_return)\n",
    "mlp_table.append(mlp_return)\n",
    "knn_table.append(knn_return)\n",
    "rf_table.append(rf_return)\n",
    "lr_table.append(lr_return)\n",
    "dt_table.append(dt_return)\n",
    "# svm_table.append(svm_return)\n",
    "     \n",
    "# svm_table_final = DataFrame(svm_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "#                                                 \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "gauu_nb_table_final = DataFrame(gauu_nb_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "mlp_table_final = DataFrame(mlp_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "knn_table_final = DataFrame(knn_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "rf_table_final = DataFrame(rf_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "lr_table_final = DataFrame(lr_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "\n",
    "dt_table_final = DataFrame(dt_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 (weighted)</th>\n",
       "      <th>F1 (Macro)</th>\n",
       "      <th>F1 (Micro)</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.932977</td>\n",
       "      <td>0.870446</td>\n",
       "      <td>0.932977</td>\n",
       "      <td>0.900627</td>\n",
       "      <td>0.321775</td>\n",
       "      <td>0.932977</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.932873</td>\n",
       "      <td>0.886083</td>\n",
       "      <td>0.932873</td>\n",
       "      <td>0.900711</td>\n",
       "      <td>0.322601</td>\n",
       "      <td>0.932873</td>\n",
       "      <td>0.500323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.926587</td>\n",
       "      <td>0.908187</td>\n",
       "      <td>0.926587</td>\n",
       "      <td>0.915659</td>\n",
       "      <td>0.448742</td>\n",
       "      <td>0.926587</td>\n",
       "      <td>0.580523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.941485</td>\n",
       "      <td>0.930270</td>\n",
       "      <td>0.941485</td>\n",
       "      <td>0.933009</td>\n",
       "      <td>0.557534</td>\n",
       "      <td>0.941485</td>\n",
       "      <td>0.640535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.932977</td>\n",
       "      <td>0.870446</td>\n",
       "      <td>0.932977</td>\n",
       "      <td>0.900627</td>\n",
       "      <td>0.321775</td>\n",
       "      <td>0.932977</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.910821</td>\n",
       "      <td>0.916018</td>\n",
       "      <td>0.910821</td>\n",
       "      <td>0.913331</td>\n",
       "      <td>0.513490</td>\n",
       "      <td>0.910821</td>\n",
       "      <td>0.654679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Precision    Recall  F1 (weighted)  F1 (Macro)  F1 (Micro)  \\\n",
       "NB   0.932977   0.870446  0.932977       0.900627    0.321775    0.932977   \n",
       "MLP  0.932873   0.886083  0.932873       0.900711    0.322601    0.932873   \n",
       "KNN  0.926587   0.908187  0.926587       0.915659    0.448742    0.926587   \n",
       "RF   0.941485   0.930270  0.941485       0.933009    0.557534    0.941485   \n",
       "LR   0.932977   0.870446  0.932977       0.900627    0.321775    0.932977   \n",
       "DT   0.910821   0.916018  0.910821       0.913331    0.513490    0.910821   \n",
       "\n",
       "      ROC AUC  \n",
       "NB   0.500000  \n",
       "MLP  0.500323  \n",
       "KNN  0.580523  \n",
       "RF   0.640535  \n",
       "LR   0.500000  \n",
       "DT   0.654679  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking average of all k-fold performance values\n",
    "final_mean_mat = []\n",
    "\n",
    "# final_mean_mat.append(np.transpose((list(svm_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(gauu_nb_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(mlp_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(knn_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(rf_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(lr_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(dt_table_final.mean()))))\n",
    "\n",
    "final_avg_mat = DataFrame(final_mean_mat,columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"], \n",
    "                          index=[\"NB\",\"MLP\",\"KNN\",\"RF\",\"LR\",\"DT\"])\n",
    "\n",
    "final_avg_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split Done\n",
      "X_train rows =  9598 X_train columns =  19\n",
      "X_test rows =  86386 X_test columns =  19\n",
      "Data reduction using kernel Done@@@@@@@@@@@@@@\n",
      "unique labels =  [0 1 2]\n",
      "Epoch 1/10\n",
      "87/87 [==============================] - 10s 5ms/step - loss: 10762.3258 - accuracy: 0.0796 - val_loss: 229.0894 - val_accuracy: 0.9312\n",
      "Epoch 2/10\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 193.7614 - accuracy: 0.9315 - val_loss: 19.5105 - val_accuracy: 0.9271\n",
      "Epoch 3/10\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 9.2148 - accuracy: 0.9043 - val_loss: 7.6271 - val_accuracy: 0.9292\n",
      "Epoch 4/10\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 6.1796 - accuracy: 0.9118 - val_loss: 8.0393 - val_accuracy: 0.9135\n",
      "Epoch 5/10\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 5.9936 - accuracy: 0.9124 - val_loss: 6.3682 - val_accuracy: 0.8927\n",
      "Epoch 6/10\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 7.3207 - accuracy: 0.9022 - val_loss: 6.6853 - val_accuracy: 0.9073\n",
      "Epoch 7/10\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 4.5182 - accuracy: 0.9082 - val_loss: 5.2433 - val_accuracy: 0.8542\n",
      "Epoch 8/10\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 5.2092 - accuracy: 0.9005 - val_loss: 4.6046 - val_accuracy: 0.7917\n",
      "Epoch 9/10\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 4.6572 - accuracy: 0.9030 - val_loss: 3.9351 - val_accuracy: 0.8198\n",
      "Epoch 10/10\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 4.7939 - accuracy: 0.8907 - val_loss: 9.8028 - val_accuracy: 0.9312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Classifier Total Time in seconds => 11.582735776901245\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "X = X_orig\n",
    "y =  np.array(labels_int)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.9)\n",
    "sss.get_n_splits(X, y)\n",
    "train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "print(\"Train-Test Split Done\")\n",
    "\n",
    "    \n",
    "print(\"X_train rows = \",len(X_train),\"X_train columns = \",len(X_train[0]))\n",
    "print(\"X_test rows = \",len(X_test),\"X_test columns = \",len(X_test[0]))\n",
    "\n",
    "#print(\"Random Fourier Features Starts here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "\n",
    "#start_time = time.time()\n",
    "#rbf_feature = RBFSampler(gamma=1, n_components=500)\n",
    "#rbf_feature.fit(X_train)\n",
    "#X_features_train = rbf_feature.transform(X_train)\n",
    "#X_features_test = rbf_feature.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Data reduction using kernel Done@@@@@@@@@@@@@@\")\n",
    "\n",
    "unique_labels = np.unique(y)\n",
    "print(\"unique labels = \",np.unique(y))\n",
    "\n",
    "# https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
    "aaa = (X_train.shape)\n",
    "MAX_NB_WORDS = aaa[1]\n",
    "EMBEDDING_DIM = 500\n",
    "Memory_Units = 200\n",
    "epochs = 10 # one epoch = one forward pass and one backward pass of all the training examples\n",
    "batch_size = 100 # the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=np.array(X).shape[1]))\n",
    "#model.add(LSTM(Memory_Units, dropout=0.2, recurrent_dropout=0.2))\n",
    "##model.add(Dense(EMBEDDING_DIM, activation='relu'))\n",
    "#model.add(Dense(max(unique_labels)+1, activation='softmax'))\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# define baseline model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(MAX_NB_WORDS, input_dim=np.array(X).shape[1], activation='relu'))\n",
    "\tmodel.add(Dense(max(unique_labels)+1, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "start_time = time.time()\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=epochs, batch_size=batch_size, validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "\n",
    "estimator.fit(X_train, y_train)\n",
    "y_pred = estimator.predict(X_test)\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "print(\"Keras Classifier Total Time in seconds =>\",end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score [0.9314124973954113, 0.8677791685333658, 0.9314124973954113, 0.8984705497000357, 0.3214961411752484, 0.9314124973954113, 0.49995063894183284]\n"
     ]
    }
   ],
   "source": [
    "RC_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "RC_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "RC_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "RC_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "RC_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "RC_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "confuse = confusion_matrix(y_test, y_pred)\n",
    "y_prob = y_pred\n",
    "macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "\n",
    "check = [RC_acc,RC_prec,RC_recall,RC_f1_weighted,RC_f1_macro,RC_f1_micro,macro_roc_auc_ovo[1]]\n",
    "\n",
    "print(\"Final score\",check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from keras_fsl.models.encoders import BasicCNN\n",
    "from keras_fsl.layers import GramMatrix\n",
    "from keras_fsl.losses.gram_matrix_losses import BinaryCrossentropy\n",
    "from keras_fsl.metrics.gram_matrix_metrics import classification_accuracy, min_eigenvalue\n",
    "from keras_fsl.utils.tensors import get_dummies\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_orig\n",
    "y =  np.array(labels_int)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.9)\n",
    "sss.get_n_splits(X, y)\n",
    "train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset omniglot/3.0.0 (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\sali85\\tensorflow_datasets\\omniglot\\3.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149b72858e6f409a8c109d6bcf3171eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Dl Completed...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d614d49499a24389892d29244587c545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Dl Size...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e629ad784fa43d7a561769dc3279504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Extraction completed...'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ExtractError",
     "evalue": "Error while extracting C:\\Users\\sali85\\tensorflow_datasets\\downloads\\brend_omnig_raw_maste_pytho_image_evalubGVoN2jrejt9ilVCYaN4mqEREeA_1qeml3UWyWtc3N8.zip to C:\\Users\\sali85\\tensorflow_datasets\\downloads\\extracted\\ZIP.brend_omnig_raw_maste_pytho_image_evalubGVoN2jrejt9ilVCYaN4mqEREeA_1qeml3UWyWtc3N8.zip (file: images_evaluation\\Old_Church_Slavonic_(Cyrillic)\\character01\\1389_01.png) : Failed to create a directory: C:\\Users\\sali85\\tensorflow_datasets\\downloads\\extracted\\ZIP.brend_omnig_raw_maste_pytho_image_evalubGVoN2jrejt9ilVCYaN4mqEREeA_1qeml3UWyWtc3N8.zip.incomplete_6e3fc6c631ac4049a5524c004f74d4bf\\images_evaluation/Old_Church_Slavonic_(Cyrillic)/character01; No such file or directory\nOn windows, path lengths greater than 260 characters may result in an error. See the doc to remove the limiration: https://docs.python.org/3/using/windows.html#removing-the-max-path-limitation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\download\\extractor.py\u001b[0m in \u001b[0;36m_sync_extract\u001b[1;34m(self, from_path, method, to_path)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mdst_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_path_tmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mto_path_tmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0m_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\download\\extractor.py\u001b[0m in \u001b[0;36m_copy\u001b[1;34m(src_file, dest_path)\u001b[0m\n\u001b[0;32m    119\u001b[0m   \u001b[1;34m\"\"\"Copy data read from src file obj to new file in dest_path.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m   \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdest_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    513\u001b[0m   \"\"\"\n\u001b[1;32m--> 514\u001b[1;33m   \u001b[0m_pywrap_file_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecursivelyCreateDir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_to_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Failed to create a directory: C:\\Users\\sali85\\tensorflow_datasets\\downloads\\extracted\\ZIP.brend_omnig_raw_maste_pytho_image_evalubGVoN2jrejt9ilVCYaN4mqEREeA_1qeml3UWyWtc3N8.zip.incomplete_6e3fc6c631ac4049a5524c004f74d4bf\\images_evaluation/Old_Church_Slavonic_(Cyrillic)/character01; No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mExtractError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-7bf2029fead8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m train_dataset, val_dataset, test_dataset = [\n\u001b[0;32m      3\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_image_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"omniglot\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train[:90%]\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"train[90%:]\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_supervised\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m ]\n\u001b[0;32m      6\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# first shape is batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wrapt\\wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[1;31m# wrapped using the staticmethod decorator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m         return self._self_wrapper(self.__wrapped__, self._self_instance,\n\u001b[0m\u001b[0;32m    567\u001b[0m                 args, kwargs)\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[1;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    369\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m     \u001b[0mdbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload_and_prepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mas_dataset_kwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wrapt\\wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    603\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m             return self._self_wrapper(self.__wrapped__, self._self_instance,\n\u001b[0m\u001b[0;32m    606\u001b[0m                     args, kwargs)\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[1;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[1;34m(self, download_dir, download_config)\u001b[0m\n\u001b[0;32m    372\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_from_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m           self._download_and_prepare(\n\u001b[0m\u001b[0;32m    375\u001b[0m               \u001b[0mdl_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m               download_config=download_config)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[1;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[0;32m   1015\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_download_and_prepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m     \u001b[1;31m# Extract max_examples_per_split and forward it to _prepare_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m     super(GeneratorBasedBuilder, self)._download_and_prepare(\n\u001b[0m\u001b[0;32m   1018\u001b[0m         \u001b[0mdl_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m         \u001b[0mmax_examples_per_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_examples_per_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[1;34m(self, dl_manager, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m    936\u001b[0m     split_generators_kwargs = self._make_split_generators_kwargs(\n\u001b[0;32m    937\u001b[0m         prepare_split_kwargs)\n\u001b[1;32m--> 938\u001b[1;33m     for split_generator in self._split_generators(\n\u001b[0m\u001b[0;32m    939\u001b[0m         dl_manager, **split_generators_kwargs):\n\u001b[0;32m    940\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"all\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\image_classification\\omniglot.py\u001b[0m in \u001b[0;36m_split_generators\u001b[1;34m(self, dl_manager)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_split_generators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0mextracted_dirs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload_and_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_DL_URLS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;31m# Get all alphabets and labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py\u001b[0m in \u001b[0;36mdownload_and_extract\u001b[1;34m(self, url_or_urls)\u001b[0m\n\u001b[0;32m    602\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_downloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_map_promise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_download_extract\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl_or_urls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py\u001b[0m in \u001b[0;36m_map_promise\u001b[1;34m(map_fn, all_inputs)\u001b[0m\n\u001b[0;32m    639\u001b[0m   \u001b[1;34m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m   \u001b[0mall_promises\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_inputs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Apply the function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m   \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_wait_on_promise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_promises\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py\u001b[0m in \u001b[0;36m_wait_on_promise\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wait_on_promise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\promise\\promise.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mDEFAULT_TIMEOUT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_target_settled_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_raise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_target_settled_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_raise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\promise\\promise.py\u001b[0m in \u001b[0;36m_target_settled_value\u001b[1;34m(self, _raise)\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_target_settled_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_raise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;31m# type: (bool) -> Any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_settled_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_raise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_reason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_target_settled_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\promise\\promise.py\u001b[0m in \u001b[0;36m_settled_value\u001b[1;34m(self, _raise)\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0m_raise\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                 \u001b[0mraise_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fulfillment_handler0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m                 \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraise_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_traceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fulfillment_handler0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\promise\\promise.py\u001b[0m in \u001b[0;36mhandle_future_result\u001b[1;34m(future)\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;31m# type: (Any) -> None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 844\u001b[1;33m             \u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\thread.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\download\\extractor.py\u001b[0m in \u001b[0;36m_sync_extract\u001b[1;34m(self, from_path, method, to_path)\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[1;34m'https://docs.python.org/3/using/windows.html#removing-the-max-path-limitation'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         )\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mExtractError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[1;31m# `tf.io.gfile.Rename(overwrite=True)` doesn't work for non empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# directories, so delete destination first, if it already exists.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExtractError\u001b[0m: Error while extracting C:\\Users\\sali85\\tensorflow_datasets\\downloads\\brend_omnig_raw_maste_pytho_image_evalubGVoN2jrejt9ilVCYaN4mqEREeA_1qeml3UWyWtc3N8.zip to C:\\Users\\sali85\\tensorflow_datasets\\downloads\\extracted\\ZIP.brend_omnig_raw_maste_pytho_image_evalubGVoN2jrejt9ilVCYaN4mqEREeA_1qeml3UWyWtc3N8.zip (file: images_evaluation\\Old_Church_Slavonic_(Cyrillic)\\character01\\1389_01.png) : Failed to create a directory: C:\\Users\\sali85\\tensorflow_datasets\\downloads\\extracted\\ZIP.brend_omnig_raw_maste_pytho_image_evalubGVoN2jrejt9ilVCYaN4mqEREeA_1qeml3UWyWtc3N8.zip.incomplete_6e3fc6c631ac4049a5524c004f74d4bf\\images_evaluation/Old_Church_Slavonic_(Cyrillic)/character01; No such file or directory\nOn windows, path lengths greater than 260 characters may result in an error. See the doc to remove the limiration: https://docs.python.org/3/using/windows.html#removing-the-max-path-limitation"
     ]
    }
   ],
   "source": [
    "#%% Get data\n",
    "train_dataset, val_dataset, test_dataset = [\n",
    "    dataset.shuffle(1024).batch(64).map(lambda x, y: (tf.image.convert_image_dtype(x, tf.float32), get_dummies(y)[0]))\n",
    "    for dataset in tfds.load(name=\"omniglot\", split=[\"train[:90%]\", \"train[90%:]\", \"test\"], as_supervised=True)\n",
    "]\n",
    "input_shape = next(tfds.as_numpy(train_dataset.take(1)))[0].shape[1:]  # first shape is batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-2068955bb859>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#%% Training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBasicCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msupport_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGramMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"DenseSigmoid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msupport_layer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBinaryCrossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclassification_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_eigenvalue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_fsl\\models\\encoders\\basic_cnn.py\u001b[0m in \u001b[0;36mBasicCNN\u001b[1;34m(input_shape, classes)\u001b[0m\n\u001b[0;32m      6\u001b[0m     model = Sequential(\n\u001b[0;32m      7\u001b[0m         [\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"same\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"same\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m    658\u001b[0m                \u001b[0mbias_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m                **kwargs):\n\u001b[1;32m--> 660\u001b[1;33m     super(Conv2D, self).__init__(\n\u001b[0m\u001b[0;32m    661\u001b[0m         \u001b[0mrank\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, conv_op, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m                \u001b[0mconv_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m                **kwargs):\n\u001b[1;32m--> 129\u001b[1;33m     super(Conv, self).__init__(\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m         \u001b[0mbatch_input_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_shape'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_input_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#%% Training\n",
    "encoder = BasicCNN(input_shape=len(X_train))\n",
    "support_layer = GramMatrix(kernel=\"DenseSigmoid\")\n",
    "model = Sequential([encoder, support_layer])\n",
    "model.compile(optimizer=\"Adam\", loss=BinaryCrossentropy(), metrics=[classification_accuracy(), min_eigenvalue])\n",
    "model.fit(X_train, validation_data=val_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/sicara/easy-few-shot-learning.git\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-Training:   0%|                                                                            | 0/19 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.int32 object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-f41dfd71ffab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\easyfsl\\methods\\abstract_meta_learner.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_loader, optimizer, val_loader, validation_frequency)\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Meta-Training\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         ) as tqdm_train:\n\u001b[1;32m--> 198\u001b[1;33m             for episode_index, (\n\u001b[0m\u001b[0;32m    199\u001b[0m                 \u001b[0msupport_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m                 \u001b[0msupport_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.int32 object"
     ]
    }
   ],
   "source": [
    "from easyfsl.methods import PrototypicalNetworks\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "convolutional_network = resnet18(pretrained=False)\n",
    "convolutional_network.fc = nn.Flatten()\n",
    "model = PrototypicalNetworks(convolutional_network)\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "optimizer = Adam(params=model.parameters())\n",
    "\n",
    "model.fit(X_train[0], optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
